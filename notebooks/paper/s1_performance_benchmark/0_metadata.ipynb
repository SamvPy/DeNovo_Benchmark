{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first section of the paper **answers the following question**:\n",
    "\n",
    "# Which de novo algorithm performs best\n",
    "\n",
    "Key questions are how to define 'best'. For this, several metrics will be used: **Peptide and amino acid recall** as defined in the review of *W. Bittremieux*.\n",
    "\n",
    "\n",
    "Previously in the first section of the *Denis Beslic* paper, 2 plot types were used:\n",
    "1. PR curves on 3 different enzymes (amino acid precision / amino acid recall) under different score thresholds\n",
    "2. AUC barplots of the PR curves in 1\n",
    "3. Barplots on 6 different enzymes with following metrics:\n",
    "    1. peptide recall\n",
    "    2. Amino acid recall\n",
    "    3. Amino acid precision\n",
    "\n",
    "This would conclude the section on performance for DB.\n",
    "\n",
    "## The flow of this section\n",
    "\n",
    "### **Accuracy of de novo tools**\n",
    "\n",
    "We start off by asking which de novo tool performs optimal.\n",
    "\n",
    "Part 1: De novo sequencing models\n",
    "\n",
    "<ins>*1.1. accuracy*</ins>\n",
    "\n",
    "To answer this, the standard metrics as utilized in the field will be used. This includes the peptide and amino acid recall and precision. However, this will only give partial insights into the relative performance of the tools. Therefore, in the next section, the 'redundancy' will be established by generating heatmaps\n",
    "\n",
    "<ins>*1.2. overlap*</ins>\n",
    "\n",
    "After seeing some tools perform similarly, the question remains whether the same spectra are correctly predicted or whether the tools perform more optimal on spectra with differing characteristics. This could indicate that a given network architecture is more suitable for certain spectra. By looking at the overlap of correctly predicted spectra, this question can be answered.\n",
    "\n",
    "A follow-up question is, whether the tools also overlap on spectra which are not correctly predicted. This can indicate false positives from the database ground-truth and is interesting to store for future analysis. This future analysis is related to rescoring/reranking and the question of ambiguity.\n",
    "\n",
    "<br>\n",
    "\n",
    "Part 2: Refinement de novo models\n",
    "\n",
    "A second type of de novo models include those that refine original de novo sequencing results in the hopes to correct small sequencing mistakes. The tools under evaluation are *Spectralis*, *InstaNovo+*, and *MS2Rescore* (PNovo3 alternative). The effect of these models on the original predictions can be subdivided in 3 distinct parts.\n",
    "\n",
    "<ins>*2.1. sequence changes*</ins>\n",
    "\n",
    "Firstly, these models **change the sequence** of the predicted peptide sequence. This is the most obvious effect of such a tool. Most use evolutionary algorithms or diffusion models to do this. To investigate this effect, one could simply look at how many of the peptide sequences that have undergone a change, were correct and if false, became correct after perturbing. A second analysis involves investigating which amino acids (or tags) are prone to change as this might indicate recurrent ambiguous sections or the propensity of an algorithm to pay attention to this particular site. (check levenschtein distance)\n",
    "\n",
    "<ins>*2.2. Re-ordering*</ins>\n",
    "\n",
    "Secondly, irrespective of changing the sequence, **a new score** is associated to each PSM by the model. This is important as de novo tools could be confident about a prediction yet did not integrate all available information such as retention time, ion mobility and simpler metrics such as ion coverage. Ignoring this information can lead to a suboptimal scoring function. Here, the rescoring aspect can re-order the PSMs over the results and thus keep the PR-curve high for longer (more correct predictions are higher scored then false predictions).\n",
    "\n",
    "<ins>*2.3. Re-ranking*</ins>\n",
    "\n",
    "Thirdly, and the focus of tools such as *pNovo3*, *PostNovo*, and *RankNovo*, is **reranking**. Distinct from rescoring and re-ordering spectra, this aspect focuses on reranking peptide predictions within a single spectrum. Indeed, in some cases, lower ranked hits might be the correct prediction, yet due to similar issues as in re-ordering, the scoring function might've been suboptimal. This aspect could indicate issues in the searching strategy employed when building up the sequence from amino acid probabilities such as in beam search in autoregressive models or graph searching in models such as PepNet and pi-PrimeNovo.\n",
    "\n",
    "After these 3 aspects are investigated, a clear image might arise how benefitial post-processing models are.\n",
    "\n",
    "\n",
    "\n",
    "## The evaluation in figures\n",
    "\n",
    "Here we will generate the following figures in the coming notebooks:\n",
    "\n",
    "### 1_1_accuracy\n",
    "\n",
    "The standard metrics are computed for the several tools.\n",
    "\n",
    "- PR plots on amino acid and peptide precision/coverage\n",
    "- barplots on peptide recall, amino acid recall and precision\n",
    "\n",
    "\n",
    "### 1_2_overlap\n",
    "\n",
    "- Heatmap on correct predictions\n",
    "- Heatmap on (commonly) false predictions\n",
    "\n",
    "### 2_1_refinement_seq\n",
    "\n",
    "- Barplot with following bars indicating the change in 'correctness' after perturbation\n",
    "    - correct vs incorrect originally\n",
    "    - correct vs incorrect after prediction\n",
    "- Barplot? showing counts of the sequence change (in terms of sequence alignment ?)\n",
    "- Kdeplot with hue (correctness) showing the sequence alignment before and after perturbation to showcase how much of the sequence was changed\n",
    "\n",
    "### 2_2_refinement_score\n",
    "\n",
    "- PR plots (engine by engine) showing the different scorings for each model\n",
    "\n",
    "### 2_3_refinement_re-ordering\n",
    "\n",
    "- Barplot (with hue rescoring model) with indices as the rank and height as number of correct predictions.\n",
    "- ?? Boxplot showing difference in scores between correct vs lower rank vs nr1 incorrect vs correct lower rank ?? this could indicate ambiguity ?\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
