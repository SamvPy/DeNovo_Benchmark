{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following question is central in the 2nd part of the paper on errors:\n",
    "\n",
    "# Why do the models make mistakes and what are these mistakes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cause of sequencing errors made by de novo algorithms can be largely subdivided in two sections: (i) Errors due to a suboptimal de novo algorithm or, (ii) inherent limitations of noisy data hindering completely accurate inference. In this section, the question related to errors in de novo sequencing is answered in two subquestions:\n",
    "\n",
    "1. How do the errors look like ?\n",
    "2. Are these errors related to data characteristics ?\n",
    "\n",
    "In the final section of this part serves as a link towards the third and final section of the paper.\n",
    "\n",
    "<ins>*1 Sequence errors*</ins>\n",
    "\n",
    "First, the error types made by the algorithms will be explored. These errors are subdivided in recent papers in the following ways.\n",
    "1. Dennis Beslic:\n",
    "    - 1 -> 1/2 amino acid replacement\n",
    "    - 2 -> 2 amino acid replacement\n",
    "    - x -> x amino acid replacement where x in [3,4,5,6]\n",
    "    - inversion of first or last 3 amino acids\n",
    "\n",
    "2. Instanovo:\n",
    "    - Subsequence error\n",
    "    - Completely wrong\n",
    "    - Subsequence reordering\n",
    "    - Added (or dropped) tokens\n",
    "\n",
    "3. Spectralis\n",
    "    - Levenshtein distance\n",
    "\n",
    "It is clear that errors can be represented in multiple ways. \n",
    "\n",
    "Of interest to me is where these errors occur and what the nature of the errors are. Thus, in this section, the errors will be counted based on location and type.\n",
    "\n",
    "*1.1. Error location*\n",
    "\n",
    "(Should we first make distinction between large or small mistakes ?)\n",
    "\n",
    "Interesting would be that the error locate at the sites where there is no sequencing evidence. Alternatively, the n- or c-term sites accumulating errors could be caused by the low intensity of terminal ion fragments, especially for longer sequences.\n",
    "\n",
    "- n- or c-terminal\n",
    "- missing fragmentation sites\n",
    "\n",
    "*1.2. Error type*\n",
    "\n",
    "Irrespective of the site of the errors, it is interesting how these errors manifest. Are these isobaric errors at sites of missing fragmentation evidence? Are these well-known errors such as the NQ-deamidation --> ED, or other 1/2 isobaric amino acid changes?\n",
    "\n",
    "Lastly, to gain an idea of the gravity of the sequencing errors, a simple metric can be computed to be compared across all tools, namely **the Levenshtein distance** as used in the *Spectralis* paper.\n",
    "\n",
    "\n",
    "<ins>*2 Spectrum characteristics*</ins>\n",
    "\n",
    "Irrespective of the actual error that was made, the reason the model makes a mistake might be due to a specific spectrum characteristic or the nature of the peptide that needs to be predicted. Here, the following features will be evaluated in their propensity to induce errors in de novo models:\n",
    "\n",
    "- Missing fragmentation sites\n",
    "- Explained intensity in percent (reverse of the noise in the spectrum)\n",
    "- Lenght of the peptide (strongly related to missing fragmentation sites)\n",
    "- Charge state\n",
    "- ...\n",
    "\n",
    "More spectrum characteristics can be included in the future, but these are it for now.\n",
    "\n",
    "<ins>*3 Are errors truly errors ?*</ins>\n",
    "\n",
    "The final section explores the possibility that some errors made by the models are in fact not errors, but a mistake in search space reduction during database construction. Here, this possibility is explored by rescoring de novo results with the ms2rescore approach after training mokapot models on the database results. The logic behind this scheme is that the model will pick up features contributing to good hits. If a better hit presents itself outside the search space, e.g. a de novo sequence, this will acquire a higher score than the database PSM. Both the binary metric (higher, lower) as the size of the gap will be interesting to explore.\n",
    "\n",
    "In the paper, we will focus on two aspects.\n",
    "\n",
    "Firstly, if a de novo PSM is scored higher or lower, this is interpretable in terms of features. Therefore, several features used to calculate the ms2rescore score will be investigated. We expect the retention times and ion mobilities to fit better for database hits when de novo is bad, etc... [see notebook: 0_merge_results in PXD028735]\n",
    "\n",
    "Secondly, the de novo hits might differ only slightly from the true hits according to the score-difference boxplots, begging the question whether some of these mistakes are truly mistakes or just unsolvable with de novo sequencing. (stacked barplot here with missing fragmentations and error types [notebook: get_features_from_psm in scrap_notes])\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "By concluding the section with questioning the mistakes made by de novo altogether, we allow to go a bit deeper on this aspect and steer the minds of the readers towards the advantages and disadvantages of database and de novo searching. Furthermore, thanks to this section we can make some claims about how FDR of de novo sequencing results should look like. Indeed, instead of looking run-wide towards characteristics of PSMs, spectrum-by-spectrum, we should look within a single spectrum and ask ourselves if this is solvable in a larger search space. Search space is here the biggest determinant of solvability as with databases we make solvability artificially high, which is not necessarily a bad thing. The final section will deal with the issue of solvability and make some preliminary attempts towards this.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots to be made\n",
    "\n",
    "## 1_error_seq\n",
    "\n",
    "- Plot with Levenshtein distances per tool (boxplot / **barplot**). x-axis: levenshtein distance, y-axis: PSM count, hue: tool\n",
    "- Filter PSMs on levenshtein distance [0, 2]: Countplot errors per tool\n",
    "- Barplot showing N-term, C-term, MF errors\n",
    "\n",
    "## 2_error_spectrum\n",
    "\n",
    "- Stacked barplots per feature when taking the best de novo match. Put countplot besides it how many times a PSM of a given tool was selected.\n",
    "    - pep length\n",
    "    - MF sites\n",
    "    - charge\n",
    "    - Explained intensity (bins)\n",
    "\n",
    "## 3_error_question\n",
    "\n",
    "- Plot score differences in boxplots.\n",
    "- Take non-matching. Split in higher and lower. Show distribution of RT, MS2PIP, (IM), hyperscore (...) if de novo is better (plot above) or worse (plot below). The hue shows also the database feature for those spectra\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
